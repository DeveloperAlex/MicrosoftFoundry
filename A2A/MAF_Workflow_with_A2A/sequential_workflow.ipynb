{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74ae4dd4",
   "metadata": {},
   "source": [
    "## MS Learn Path Builder with Microsoft Agent Framework (MAF) and A2A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b87c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install a2a-sdk==0.3.8 agent-framework==1.0.0b251209 azure-ai-projects==2.0.0b2 python-dotenv azure-identity uvicorn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbeca87",
   "metadata": {},
   "source": [
    "### Setting Up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f00ba473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Endpoint:  https://carbonopsdevai4434735199.services.ai.azure.com/api/projects/demo-proj\n",
      "Model:  gpt-4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "load_dotenv()\n",
    "project_endpoint = os.getenv(\"FOUNDRY_PROJECT_ENDPOINT\")\n",
    "model = os.getenv(\"MODEL_DEPLOYMENT_NAME\")\n",
    "\n",
    "print(\"Project Endpoint: \", project_endpoint)\n",
    "print(\"Model: \", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d1e43c",
   "metadata": {},
   "source": [
    "### Defining the Function to Create a Chat Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c16a37e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import ChatAgent\n",
    "from agent_framework.azure import AzureAIClient\n",
    "from azure.ai.projects.aio import AIProjectClient\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "\n",
    "# Cell 2: Define async workflow\n",
    "async def create_agent(agent_name: str,\n",
    "                       agent_instructions: str) -> ChatAgent:\n",
    "    \n",
    "    # Create async Azure credential\n",
    "    credential = AzureCliCredential()\n",
    "\n",
    "    # creating the Foundry Project Client\n",
    "    project_client = AIProjectClient(\n",
    "        endpoint=project_endpoint,\n",
    "        credential=credential\n",
    "    )\n",
    "\n",
    "    # creating a conversation using the OpenAI Client\n",
    "    openai_client = project_client.get_openai_client()\n",
    "    conversation = await openai_client.conversations.create()\n",
    "    conversation_id = conversation.id\n",
    "    print(\"Conversation ID: \", conversation_id)\n",
    "    \n",
    "    # Initialize the Azure AI Agent Client\n",
    "    chat_client = AzureAIClient(project_client=project_client,\n",
    "                                conversation_id=conversation_id,\n",
    "                                model_deployment_name=model)\n",
    "\n",
    "    try:\n",
    "        agent = chat_client.create_agent(\n",
    "            name=agent_name,\n",
    "            instructions=agent_instructions,\n",
    "        )\n",
    "\n",
    "        print(\"{} Agent created successfully!\".format(agent_name))\n",
    "        return agent\n",
    "\n",
    "    finally:\n",
    "        # Clean up async clients\n",
    "        await chat_client.close()\n",
    "        await credential.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b93631",
   "metadata": {},
   "source": [
    "### Creating the Topic Generator Agent - Pure Foundry Based Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59a955bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation ID:  conv_2e02dbdc05c7bf7d00gFYeek1OG9ci6BW2u9l1BBlB0MGEGZrh\n",
      "Topic-Generator-Agent Agent created successfully!\n"
     ]
    }
   ],
   "source": [
    "topic_generator_agent = await create_agent(\n",
    "    agent_name = \"Topic-Generator-Agent\",\n",
    "    agent_instructions = \"You are a helpful assistant that generates a list of topics for Microsoft Learn learning paths based on user input.\"\n",
    "                         \"Your response should be a concise list of topics relevant to the user's interests in a structured format.\"\n",
    ")     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c06e57",
   "metadata": {},
   "source": [
    "### Creating the MS Learn Path Builder Agent - A2A Based Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7b9229d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched public agent card:\n",
      "Name: MS Learn Path Builder Agent with Foundry A2A\n"
     ]
    }
   ],
   "source": [
    "from httpx import AsyncClient\n",
    "from a2a.types import AgentCard, Message, Part, Role, Task, TextPart\n",
    "from a2a.client import ClientFactory, Client\n",
    "from a2a.client.card_resolver import A2ACardResolver\n",
    "from a2a.client.client import ClientConfig\n",
    "from a2a.types import TransportProtocol\n",
    "from a2a.client import create_text_message_object\n",
    "from a2a.utils.message import get_message_text\n",
    "import httpx\n",
    "from agent_framework.a2a import A2AAgent\n",
    "\n",
    "base_url = \"http://localhost:8080\"\n",
    "\n",
    "final_agent_card: AgentCard | None = None\n",
    "\n",
    "# creating the httpx client with custom timeouts\n",
    "async with httpx.AsyncClient(\n",
    "    timeout=httpx.Timeout(\n",
    "        connect=10.0,\n",
    "        read=60.0,\n",
    "        write=10.0,\n",
    "        pool=10.0,\n",
    "            )) as httpx_client:\n",
    "    \n",
    "    # creating the A2ACardResolver\n",
    "    resolver = A2ACardResolver(\n",
    "        httpx_client=httpx_client,\n",
    "        base_url=base_url\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Attempting to fetch public agent card from custom path\n",
    "        _public_card = (\n",
    "                await resolver.get_agent_card()\n",
    "            )  # Fetches from default public path\n",
    "\n",
    "        final_agent_card = _public_card\n",
    "\n",
    "        print('Successfully fetched public agent card:')\n",
    "        print(f'Name: {_public_card.name}')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Critical error fetching public agent card: {e}', exc_info=True)  \n",
    "        raise RuntimeError(\n",
    "                'Failed to fetch the public agent card. Cannot continue.'\n",
    "            ) from e\n",
    "    \n",
    "    # Creating the A2A Agent finally in Microsoft Agent Framework\n",
    "    ms_learn_path_builder_agent = A2AAgent(\n",
    "    name = final_agent_card.name,\n",
    "    description = final_agent_card.description,\n",
    "    agent_card = final_agent_card,\n",
    "    url = \"https://localhost:8080\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbf9253",
   "metadata": {},
   "source": [
    "### Creating the First Executor to run the Topic Generator Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d6147af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import WorkflowBuilder, WorkflowContext, WorkflowOutputEvent, executor\n",
    "from typing import Any\n",
    "from agent_framework import ChatResponse\n",
    "\n",
    "@executor(id = \"run_topic_generator_agent\")\n",
    "async def run_topic_generator_agent(query: str,\n",
    "                               ctx: WorkflowContext[str]) -> None:\n",
    "    response = await topic_generator_agent.run(query)\n",
    "\n",
    "    await ctx.send_message(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa09dfb9",
   "metadata": {},
   "source": [
    "### Creating the Second Executor to run the MS Learn Path Builder Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0883dcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@executor(id = \"run_ms_learn_path_builder_agent\")\n",
    "async def run_ms_learn_path_builder_agent(research_data: str,\n",
    "                          ctx: WorkflowContext[str]) -> None:\n",
    "    response = await ms_learn_path_builder_agent.run(research_data)\n",
    "    \n",
    "    final_output = \"\"\n",
    "\n",
    "    for message in response.messages:\n",
    "        final_output += message.text + \"\\n\"\n",
    "\n",
    "    await ctx.yield_output(final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a83723",
   "metadata": {},
   "source": [
    "### Creating the Sequential Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04697310",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding an edge with Executor or AgentProtocol instances directly is not recommended, because workflow instances created from the builder will share the same executor/agent instances. Consider using a registered name for lazy initialization instead.\n"
     ]
    }
   ],
   "source": [
    "from agent_framework import WorkflowBuilder, WorkflowViz\n",
    "\n",
    "workflow = (\n",
    "    WorkflowBuilder()\n",
    "    .add_edge(run_topic_generator_agent, run_ms_learn_path_builder_agent)\n",
    "    .set_start_executor(run_topic_generator_agent)\n",
    "    .build()\n",
    ")\n",
    "\n",
    "viz = WorkflowViz(workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbc56c2",
   "metadata": {},
   "source": [
    "### Running the Workflow and Streaming Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21955c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the workflow and stream events in notebook\n",
    "async def main():\n",
    "    async for event in workflow.run_stream(\"Help me Learn about Azure AI services.\"):\n",
    "        print(f\"Event: {event}\")\n",
    "        if isinstance(event, WorkflowOutputEvent):\n",
    "            print(f\"Workflow completed with result: {event.data}\")\n",
    "\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
